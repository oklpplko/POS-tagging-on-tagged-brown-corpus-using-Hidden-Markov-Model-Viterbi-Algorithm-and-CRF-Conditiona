{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "h825yHjauJSh",
    "outputId": "535e10cb-cd61-49e8-ad4c-9d732702def7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn-crfsuite\n",
      "  Downloading https://files.pythonhosted.org/packages/25/74/5b7befa513482e6dee1f3dd68171a6c9dfc14c0eaa00f885ffeba54fe9b0/sklearn_crfsuite-0.3.6-py2.py3-none-any.whl\n",
      "Requirement already satisfied: six in c:\\users\\tk\\anaconda3\\lib\\site-packages (from sklearn-crfsuite) (1.12.0)\n",
      "Collecting python-crfsuite>=0.8.3 (from sklearn-crfsuite)\n",
      "  Downloading https://files.pythonhosted.org/packages/87/07/91b578dabc20e78f77aa51dc2e1570099b9b4cc2f7f437a7007d212be464/python_crfsuite-0.9.6-cp37-cp37m-win_amd64.whl (154kB)\n",
      "Requirement already satisfied: tqdm>=2.0 in c:\\users\\tk\\anaconda3\\lib\\site-packages (from sklearn-crfsuite) (4.32.1)\n",
      "Collecting tabulate (from sklearn-crfsuite)\n",
      "  Downloading https://files.pythonhosted.org/packages/c2/fd/202954b3f0eb896c53b7b6f07390851b1fd2ca84aa95880d7ae4f434c4ac/tabulate-0.8.3.tar.gz (46kB)\n",
      "Building wheels for collected packages: tabulate\n",
      "  Building wheel for tabulate (setup.py): started\n",
      "  Building wheel for tabulate (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\TK\\AppData\\Local\\pip\\Cache\\wheels\\2b\\67\\89\\414471314a2d15de625d184d8be6d38a03ae1e983dbda91e84\n",
      "Successfully built tabulate\n",
      "Installing collected packages: python-crfsuite, tabulate, sklearn-crfsuite\n",
      "Successfully installed python-crfsuite-0.9.6 sklearn-crfsuite-0.3.6 tabulate-0.8.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sklearn-crfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "ZTeKqToKuMdo",
    "outputId": "c44ef91a-829f-4761-efde-4084000db5e9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\TK\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n",
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\TK\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\brown.zip.\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\TK\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\universal_tagset.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import treebank,brown\n",
    "from nltk import bigrams, ngrams, trigrams\n",
    "import math\n",
    "import copy\n",
    "import sklearn\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "nltk.download('treebank')\n",
    "nltk.download('brown')\n",
    "nltk.download('universal_tagset')\n",
    "nltk_data = list(nltk.corpus.treebank.tagged_sents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h9dvTu1yuSjJ"
   },
   "outputs": [],
   "source": [
    "corpus = brown.tagged_sents(tagset='universal')[:-100] \n",
    "\n",
    "tag_dict={}\n",
    "word_dict={}\n",
    "\n",
    "for sent in corpus:\n",
    "    for elem in sent:\n",
    "        w = elem[0]\n",
    "        tag= elem[1]\n",
    "\n",
    "        if w not in word_dict:\n",
    "            word_dict[w]=0\n",
    "\n",
    "        if tag not in tag_dict:\n",
    "            tag_dict[tag]=0\n",
    "\n",
    "        word_dict[w]+=1\n",
    "        tag_dict[tag]+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fhvwsSAqqK9b"
   },
   "source": [
    "The project does POS tagging on tagged brown corpus using Hidden Markov Model (Viterbi Algorithm) and CRF (Conditional Random Fields)\n",
    "\n",
    "Before we use the probabilistic methods mentioned above to tag the words, it is necessary for us to do the data preparation such as splitting the data in to Training and Test data. Brown Corpus was compiled in the 1960s by Henry Kučera and W. Nelson Francis at Brown University, Providence, Rhode Island as a general corpus (text collection) in the field of corpus linguistics. It contains 500 samples of English-language text, totaling roughly one million words, compiled from works published in the United States in 1961.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2TN8jfpo7k0N"
   },
   "outputs": [],
   "source": [
    "'''-----------------Build Start, Transition and Emission Matrix-----------------'''\n",
    "start={}\n",
    "for i in corpus:\n",
    "    if i[0] not in start:\n",
    "        start[i[0][1]]= 0\n",
    "for i in corpus:\n",
    "    start[i[0][1]]+=1\n",
    "\n",
    "for i in start:\n",
    "    start[i]=math.log2(start[i]/len(corpus))\n",
    "    \n",
    "transition={}\n",
    "transition1 = {}\n",
    "for i in corpus:\n",
    "    for j in range(len(i)-1):\n",
    "        if i[j][1] not in transition1:\n",
    "            transition1[i[j][1]]={}\n",
    "        if i[j+1][1] not in transition1[i[j][1]]:\n",
    "            transition1[i[j][1]][i[j+1][1]]=0\n",
    "        transition1[i[j][1]][i[j+1][1]]+=1\n",
    "transition= copy.deepcopy(transition1)        \n",
    "for w1 in transition:\n",
    "    tot = float(sum(transition[w1].values()))\n",
    "    for w2 in transition[w1]:\n",
    "        transition[w1][w2]=math.log2((0.001+ transition[w1][w2])/(0.001*len(word_dict) + tot))\n",
    "        \n",
    "transition_data={}\n",
    "for key,value in transition.items():\n",
    "    for key1,value1 in value.items():\n",
    "        transition_data[(key,key1)]=value1\n",
    "        \n",
    "        \n",
    "emission={}\n",
    "for i in corpus:\n",
    "    for j in range(len(i)):\n",
    "        if i[j][1] not in emission:\n",
    "            emission[i[j][1]]={}\n",
    "        if i[j][0] not in emission[i[j][1]]:\n",
    "            emission[i[j][1]][i[j][0]]=0\n",
    "        emission[i[j][1]][i[j][0]]+=1\n",
    "        \n",
    "\n",
    "for w1 in emission:\n",
    "    tot = float(sum(emission[w1].values()))\n",
    "    for w2 in emission[w1]:\n",
    "        emission[w1][w2]=math.log2((emission[w1][w2]+0.001)/(0.001*len(word_dict) + tag_dict[w1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HG9PwT_Z1L7T"
   },
   "source": [
    "After that, we could start to process the POS Tagging algorithm using HMM. Given a sequence of words to be tagged, the task is to assign the most probable tag to the word. In other words, to every word w, assign the tag t that maximize the likelihood P(t/w). \n",
    "\n",
    "Since P(t/w) = P(w/t). P(t) / P(w), after ignoring P(w), we have to compute P(w/t) and P(t). \n",
    "\n",
    "As a result: \n",
    "P(w/t): is the emission probability of a given word for a given tag. This can be computed based on the fraction of given word for given tag to the total count of that tag, ie: P(w/t) = count(w, t) / count(t). \n",
    "\n",
    "P(t): is the probability of tag (also transition probability), and in a tagging task, we assume that a tag will depend only on the previous tag (Markov order 1 assumption). In other words, the probability of telling a tag being NN will depend only on the previous tag t(n-1). For example, if t(n-1) is a JJ, then t(n) is likely to be an NN since adjectives often precede a noun (blue coat, tall building etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P_Ba5dRB2GP5"
   },
   "outputs": [],
   "source": [
    "'''--------------------Viterbi Algorithm--------------------------------'''\n",
    "\n",
    "\n",
    "test_data= brown.tagged_sents(tagset='universal')[-10:]\n",
    "sentences =[]\n",
    "for i in test_data:\n",
    "    temp = [j[0] for j in i]\n",
    "    sentences.append(temp)\n",
    "\n",
    "average = 0    \n",
    "seq = []\n",
    "def find_max(i,dic):\n",
    "    maxi = -999999\n",
    "    \n",
    "    tag=\"\"\n",
    "    for key,value in dic.items():\n",
    "        if dic[key][i] > maxi:\n",
    "            maxi = dic[key][i]\n",
    "            tag = key\n",
    "    return maxi,tag\n",
    "\n",
    "for sent in range(len(sentences)):\n",
    "    test = []\n",
    "    dic={}  \n",
    "    flag = 0\n",
    "    for i in list(tag_dict.keys()):\n",
    "        dic[i]=[]\n",
    "\n",
    "    \n",
    "    for i in sentences[sent]:\n",
    "        if flag==0:\n",
    "            for j in list(tag_dict.keys()):\n",
    "                try:\n",
    "                    prob = emission[j][i]+start[j]\n",
    "                except Exception as e:\n",
    "                    temp1 = math.log2(0.001/(0.001*len(word_dict) + tag_dict[j]))\n",
    "                    prob = start[j] + temp1\n",
    "                dic[j].append(prob)\n",
    "        break\n",
    "    \n",
    "    max_prob, tag = find_max(0,dic)\n",
    "    test.append(tag)\n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "    flag = 0\n",
    "    for i,w1 in enumerate(sentences[sent]):\n",
    "        if i==0:\n",
    "            continue\n",
    "        for j in list(tag_dict.keys()):\n",
    "            try:\n",
    "                temp = transition[tag][j]\n",
    "            except Exception as e:\n",
    "                temp = math.log2((0.001/(0.001*len(word_dict) +float(sum(transition1[tag].values())))))\n",
    "            try:\n",
    "                prob_w2 = max_prob + emission[j][w1] + temp\n",
    "            except Exception as e:\n",
    "                temp1 = math.log2(0.001/(0.001*len(word_dict) + tag_dict[j]))\n",
    "                prob_w2 = max_prob + temp1 + temp \n",
    "            dic[j].append(prob_w2)\n",
    "            \n",
    "        max_prob, tag = find_max(i,dic)\n",
    "        test.append(tag)\n",
    "    \n",
    "    seq.append(test)\n",
    "            \n",
    "        \n",
    "actual_tag=[]\n",
    "for sent in test_data:\n",
    "    temp=[]\n",
    "    for word in sent:\n",
    "        temp.append(word[1])\n",
    "    actual_tag.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wxmjTHtH2Oha"
   },
   "source": [
    "Viterbi algorithm The steps are as follows: \n",
    "1. Given a sequence of words \n",
    "\n",
    "2. iterate through the sequence \n",
    "\n",
    "3. for each word (starting from first word in sequence) calculate the product of emission probabilities and transition probabilities for all possible tags. \n",
    "\n",
    "4. assign the tag which has maximum probability obtained in step 3 above. \n",
    "\n",
    "5. move to the next word in sequence to repeat steps 3 and 4 above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T2p2Qdkh7u3H"
   },
   "outputs": [],
   "source": [
    "'''-------------------------------CRF----------------------------'''\n",
    "\n",
    "train_sents= corpus\n",
    "\n",
    "def word2features(sent,i):\n",
    "    word = sent[i][0]\n",
    "    \n",
    "    features ={\n",
    "    'bias': 1.0,\n",
    "    'word.lower()': word.lower(),\n",
    "    'word[-3:]': word[-3:],\n",
    "    'word[-2:]': word[-2:],\n",
    "    'word.isupper()': word.isupper(),\n",
    "    'word.istitle()': word.istitle(),\n",
    "    'word.isdigit()': word.isdigit(),\n",
    "    }\n",
    "    if i > 0:\n",
    "        word_prev = sent[i-1][0]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word_prev.lower(),\n",
    "            '-1:word.istitle()': word_prev.istitle(),\n",
    "            '-1:word.isupper()': word_prev.isupper(),\n",
    "        })\n",
    "    else:\n",
    "        features['start_sentence'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word_after = sent[i+1][0]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word_after.lower(),\n",
    "            '+1:word.istitle()': word_after.istitle(),\n",
    "            '+1:word.isupper()': word_after.isupper(),\n",
    "        })\n",
    "    else:\n",
    "        features['end_sentence'] = True\n",
    "                \n",
    "    return features\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent,i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for i,label in sent]\n",
    "\n",
    "\n",
    "X_train=[sent2features(s) for s in train_sents]\n",
    "y_train=[sent2labels(s) for s in train_sents]\n",
    "\n",
    "X_test=[sent2features(s) for s in test_data]\n",
    "y_test=[sent2labels(s) for s in test_data]\n",
    "\n",
    "\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs', \n",
    "    c1=0.1, \n",
    "    c2=0.1, \n",
    "    max_iterations=100, \n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = crf.predict(X_test)\n",
    "labels=list(crf.classes_)\n",
    "\n",
    "sorted_labels = sorted(\n",
    "    labels, \n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HPJQ2A6K2s0G"
   },
   "source": [
    "The next step is to use the sklearn_crfsuite to fit the CRF model. The model is optimised by Gradient Descent using the LBGS method with L1 and L2 regularisation. We will set the CRF to generate all possible label transitions, even those that do not occur in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 904
    },
    "colab_type": "code",
    "id": "dU-XV-lv7w6Y",
    "outputId": "4c84b93b-1100-4235-9263-1e01303eb1ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test sentences used = 10\n",
      "----------------------Viterbi Results---------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TK\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\TK\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Viterbi Accuracy Score : 0.9246991839814064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TK\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\TK\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           .      0.943     1.000     0.971        33\n",
      "           X      1.000     0.333     0.500         3\n",
      "         ADJ      0.941     0.889     0.914        18\n",
      "         ADP      0.962     0.926     0.943        27\n",
      "         ADV      0.800     0.889     0.842         9\n",
      "        VERB      0.941     0.914     0.928        35\n",
      "         DET      1.000     1.000     1.000        33\n",
      "        CONJ      0.636     1.000     0.778         7\n",
      "        NOUN      0.978     0.863     0.917        51\n",
      "        PRON      0.917     0.917     0.917        12\n",
      "         PRT      0.733     1.000     0.846        11\n",
      "         NUM      0.000     0.000     0.000         0\n",
      "\n",
      "   micro avg      0.925     0.925     0.925       239\n",
      "   macro avg      0.821     0.811     0.796       239\n",
      "weighted avg      0.935     0.925     0.925       239\n",
      "\n",
      "------------------------CRF Results-----------------------------\n",
      "CRF Accuracy Score : 0.9570914166105637\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           .      1.000     1.000     1.000        33\n",
      "           X      1.000     0.667     0.800         3\n",
      "         ADJ      1.000     0.778     0.875        18\n",
      "         ADP      0.962     0.926     0.943        27\n",
      "         ADV      0.900     1.000     0.947         9\n",
      "        VERB      0.946     1.000     0.972        35\n",
      "         DET      0.971     1.000     0.985        33\n",
      "        CONJ      1.000     0.857     0.923         7\n",
      "        NOUN      0.943     0.980     0.962        51\n",
      "        PRON      1.000     0.917     0.957        12\n",
      "         PRT      0.846     1.000     0.917        11\n",
      "         NUM      0.000     0.000     0.000         0\n",
      "\n",
      "   micro avg      0.958     0.958     0.958       239\n",
      "   macro avg      0.881     0.844     0.857       239\n",
      "weighted avg      0.961     0.958     0.957       239\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Number of test sentences used = 10')\n",
    "print('----------------------Viterbi Results---------------------------')\n",
    "print('Viterbi Accuracy Score :',metrics.flat_f1_score(actual_tag, seq,average='weighted', labels=labels))\n",
    "print(metrics.flat_classification_report(\n",
    "    actual_tag, seq, labels=sorted_labels, digits=3\n",
    "))\n",
    "print('------------------------CRF Results-----------------------------')\n",
    "print('CRF Accuracy Score :',metrics.flat_f1_score(y_test, y_pred, average='weighted', labels=labels))\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HeCQxNzc2x_A"
   },
   "source": [
    "Evaluating the HHM Model and CRF Model"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "1910155.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
